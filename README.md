# **An√°lisis de Sentimientos en Twitter en Tiempo Real**

Este proyecto es una herramienta integral para recolectar, analizar y visualizar tweets en tiempo real. Utiliza tecnolog√≠as avanzadas como `twikit` para scraping de Twitter y modelos preentrenados de `transformers` para an√°lisis de sentimientos. La visualizaci√≥n de los datos se realiza din√°micamente a trav√©s de gr√°ficos claros y atractivos. Este enfoque permite evaluar opiniones p√∫blicas sobre temas espec√≠ficos con un flujo constante y eficiente.

---

## **Por qu√© se eligi√≥ `twikit` en lugar del API de Twitter**

### **Limitaciones del API Oficial de Twitter**
El API oficial de Twitter tiene las siguientes desventajas significativas:
1. **Restricci√≥n en el n√∫mero de resultados**:
   - Permite un m√°ximo de 100 tweets por solicitud, lo cual no es ideal para an√°lisis masivos o en tiempo real.
   - Para obtener m√°s datos, es necesario escalar a versiones pagas que incrementan costos de forma significativa.

2. **Datos incompletos**:
   - Los tweets obtenidos suelen estar truncados si contienen enlaces largos, menciones o contenido multimedia, lo que limita el alcance y precisi√≥n del an√°lisis de sentimientos.

3. **Costos elevados**:
   - Las versiones del API con acceso extendido tienen precios altos y a√∫n mantienen restricciones de uso en cuanto a la frecuencia de solicitudes y el volumen de datos.

![Precios y Restricciones del API](./docs/06_prices_restrictions.png)

---

### **Ventajas de `twikit`**
1. **Acceso sin restricciones**:
   - `twikit` utiliza t√©cnicas de scraping directo desde la interfaz web de Twitter, permitiendo obtener una mayor cantidad de datos sin las limitaciones impuestas por el API.

2. **Datos completos y enriquecidos**:
   - Los tweets incluyen texto completo, metadatos relevantes y datos adicionales que pueden ser √∫tiles para an√°lisis m√°s detallados.

3. **Eficiencia para experimentos en tiempo real**:
   - Permite recolectar datos continuamente con mayor frecuencia, ideal para casos de uso din√°micos como eventos en curso o an√°lisis de tendencias.

![Portal de Twikit](./docs/05_x_portal.png)

---

## **Caracter√≠sticas del Proyecto**

1. **Recolecci√≥n de tweets en tiempo real**:
   - Se utiliza `twikit` para buscar y recolectar tweets relacionados con palabras clave predefinidas.
   - Los datos recolectados incluyen texto del tweet, usuario, m√©tricas de interacci√≥n (retweets, favoritos) y marcas temporales.
   - Estos datos se almacenan en un archivo CSV (`tweets_noboa.csv`), asegurando persistencia y f√°cil reutilizaci√≥n.

2. **An√°lisis de sentimientos**:
   - Utiliza el modelo preentrenado `nlptown/bert-base-multilingual-uncased-sentiment` de la librer√≠a `transformers` para clasificar los tweets en:
     - Positivos
     - Negativos
     - Neutrales
   - Este modelo es un ejemplo de transfer learning, ajustado para m√∫ltiples idiomas y espec√≠ficamente dise√±ado para tareas de an√°lisis de sentimientos.
   - Los resultados del an√°lisis se almacenan en otro archivo CSV (`tweets_sentimiento.csv`), junto con los datos originales de los tweets.

   #### **Consideraciones sobre `transformers`**:
   - **Preentrenamiento**: Los modelos en `transformers` como BERT est√°n preentrenados en grandes cantidades de texto, lo que los hace altamente efectivos para tareas de NLP.
   - **Uso de GPU**: Si se dispone de una GPU, el an√°lisis se acelera significativamente. En caso contrario, el modelo utiliza la CPU.
   - **L√≠mite de caracteres**: Debido a la arquitectura de BERT, los textos deben limitarse a 512 caracteres. El c√≥digo se encarga de realizar este ajuste autom√°ticamente.

3. **Visualizaci√≥n din√°mica**:
   - Se utiliza `matplotlib` para generar gr√°ficos en tiempo real. Incluye:
     - Un gr√°fico de barras para la distribuci√≥n de sentimientos (positivo, negativo y neutral).
     - Un gr√°fico tipo gauge que muestra el √≠ndice de popularidad, calculado como la diferencia proporcional entre tweets positivos y negativos.

---

## **Gu√≠a de Ejecuci√≥n**

### 1. **Exportar Cookies desde Twitter**
Para autenticar las solicitudes, es necesario exportar las cookies de sesi√≥n desde Twitter. Utiliza la extensi√≥n **EditThisCookie** para este prop√≥sito. 
1. Abre la p√°gina de Twitter.
2. Exporta las cookies y gu√°rdalas en un archivo llamado `cookies_exported.json`.

![Exportar Cookies](./docs/00_cookies_edit.png)

---

### 2. **Convertir las Cookies al Formato Correcto**
El script `00_cookies.py` transforma las cookies exportadas al formato requerido por `twikit`. Para ejecutar el script, usa el siguiente comando:

```bash
python 00_cookies.py
```

El resultado ser√° un archivo `cookies.json`, que se usar√° para autenticar las solicitudes.

![Conversi√≥n de Cookies](./docs/01_cookies_transformation.png)

---

### 3. **Ejecuci√≥n del Proyecto**
Ejecuta el script principal `app.py` para iniciar la recolecci√≥n y an√°lisis de tweets:

```bash
python app.py
```

#### **Procesos realizados**:
1. Recolecta tweets en tiempo real con base en las palabras clave.
2. Almacena los resultados en `tweets_noboa.csv`.
3. Aplica an√°lisis de sentimientos, cuyos resultados se almacenan en `tweets_sentimiento.csv`.
4. Muestra gr√°ficos din√°micos con los datos procesados.

![Ejecuci√≥n en Consola](./docs/02_ejecucion_consola_real_time.png)

---

### 4. **Gr√°fica de Sentimientos en Tiempo Real**
El programa genera:
1. **Gr√°fica de barras**: Representa la distribuci√≥n de sentimientos (positivo, negativo y neutral).
2. **Gauge**: Muestra el √≠ndice de popularidad, que var√≠a entre -1 (predominio negativo) y 1 (predominio positivo).

Corte 1:
![Gr√°fica de Sentimientos](./docs/03_grafica_realtime_1.png)
Corte 2:
![Gr√°fica de Sentimientos](./docs/03_grafica_realtime_2.png)
Corte 3:
![Gr√°fica de Sentimientos](./docs/03_grafica_realtime_3.png)

---

## **Requisitos Previos**

### **Dependencias**
El proyecto utiliza las siguientes librer√≠as:
- `pandas`: Para manipulaci√≥n de datos.
- `matplotlib`: Para visualizaci√≥n gr√°fica.
- `torch`: Backend para modelos de `transformers`.
- `transformers`: Librer√≠a de modelos preentrenados para tareas de NLP.
- `twikit`: Para scraping de datos de Twitter.

Instala las dependencias con:
```bash
pip install -r requirements.txt
```

### **Configuraci√≥n de Credenciales**
Crea un archivo `config.ini` con tus credenciales de Twitter. Este archivo ser√° utilizado para autenticar las solicitudes:
```ini
[X]
username = "TU_USERNAME"
email = "TU_EMAIL"
password = "TU_PASSWORD"
```

---

## **Estructura del Proyecto**

```
üìÇ TWEETSSENTIMENT
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ 00_cookies_edit.png          # Imagen de exportar cookies
‚îÇ   ‚îú‚îÄ‚îÄ 01_cookies_transformation.png # Imagen de transformaci√≥n de cookies
‚îÇ   ‚îú‚îÄ‚îÄ 02_ejecucion_consola_real_time.png # Consola de ejecuci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ 03_grafica_realtime.png      # Gr√°fica din√°mica de sentimientos
‚îÇ   ‚îú‚îÄ‚îÄ 05_x_portal.png              # Portal de Twikit
‚îÇ   ‚îî‚îÄ‚îÄ 06_prices_restrictions.png   # Precios y restricciones del API de Twitter
‚îú‚îÄ‚îÄ app.py                           # Script principal
‚îú‚îÄ‚îÄ 00_cookies.py                    # Conversi√≥n de cookies
‚îú‚îÄ‚îÄ config.ini                       # Credenciales del usuario
‚îú‚îÄ‚îÄ requirements.txt                 # Dependencias del proyecto
‚îú‚îÄ‚îÄ tweets_noboa.csv                 # Tweets recolectados
‚îú‚îÄ‚îÄ tweets_sentimiento.csv           # Tweets analizados
```

---

## **Consideraciones**

1. **L√≠mites de Scraping**:
   - Aunque `twikit` evita restricciones severas, realiza solicitudes de manera escalonada para prevenir bloqueos.

2. **Rendimiento**:
   - Se recomienda usar una GPU para acelerar el an√°lisis de sentimientos con `transformers`.

3. **Visualizaci√≥n en tiempo real**:
   - La visualizaci√≥n din√°mica asegura que los nuevos datos sean incorporados en cada actualizaci√≥n.

4. **Persistencia de Datos**:
   - Los tweets procesados se guardan para evitar duplicados en futuras ejecuciones.

---